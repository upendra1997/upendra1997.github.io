[{"content":"I recently built the for-science keyboard and I followed this guide: https://github.com/peej/for-science-keyboard\nBill of Material kit: 1800 INR arudio pro micro compatible X2: 908 INR Soldering Station: 1305 INR Soldering wire from Robocraze: 21 INR Digital Multimeter from Robocraze: 199 INR Key Switches from stackskb - Gateron G Pro 2.0 Brown KS-9 Tactile Switch - 50 pieces: 1000 INR Key Caps from stackskb - Cherry Profile Pudding Keycaps - 130 caps: 1000 INR TRRS cable from a local shop in Hyderabad: 200 INR Desoldering Flux from a local shop in Hyderabad: 350 INR Desoldering Wick from a local shop in Hyderabad: 300 INR Journey While building the keyboard, I started with following the guide mentioned above, but It was not descriptive enough so I supplemented it with other guide for Lily58.\nWhile following the guide whenever I had doubts, I referred to the gerber file here. It helped me to find which side was up by linking the TRRS jack and the pro micro\u0026rsquo;s D0 pin as mentioned here.\nMistakes I made: Bad Soldering; Advice that I will give if you are new to soldering is to practie and make sure you can solder as mentioned on this blog. I soldered the Pro Micro chip, before soldering the switches. Which caused lots of issues as I tried to fix the mistake using desoldering pumps, desoldering wicks and flux. But in the end it didn\u0026rsquo;t help and only damaged swithes and pro micro chip. Luckily I had spares swithes and few wires, so I sorted to them to make it work somehow. Lesson is to double/triple check components you are soldering, as desoldering is very painful and can damage components. The TRRS cable that I had was faulty or I spoiled it, so had to get a new TRRS cable. Lesson would be to keep cheking connectivity of your ciruit with the gerber files using the continuity mode of Multimeter. Issues that I still have with my keyboard: Right side doesn\u0026rsquo;t work individually, i.e. if I connect the keyboard to the left split it works, but If I conncet using the right split, It doesn\u0026rsquo;t. I tried this blog, but It didn\u0026rsquo;t help. Sometime the whole keyboard hangs when I am typing and starts responding after sometime. My guess is that It is happening because of all the QMK features that I have enabled on the keyboard. QMK I guess the QMK layout configuration that they had was outdated and was not working properly with my keyboard, as I built the keyboard and tested them using test-website.\nso I made few changes on my fork to make them work, and added some extra layout and features, which suited my fancy.\nImages PCB: Pro Micro: Diodes: Switches: TRRS Socket: Damaged Connection held through a metal pin: Final Keyboard HELP Please, if you find solution for above issues, please comment or reach out to me. Thank you :)\n","permalink":"https://upendra1997.github.io/posts/for-science-keyboard/","summary":"I recently built the for-science keyboard and I followed this guide: https://github.com/peej/for-science-keyboard\nBill of Material kit: 1800 INR arudio pro micro compatible X2: 908 INR Soldering Station: 1305 INR Soldering wire from Robocraze: 21 INR Digital Multimeter from Robocraze: 199 INR Key Switches from stackskb - Gateron G Pro 2.0 Brown KS-9 Tactile Switch - 50 pieces: 1000 INR Key Caps from stackskb - Cherry Profile Pudding Keycaps - 130 caps: 1000 INR TRRS cable from a local shop in Hyderabad: 200 INR Desoldering Flux from a local shop in Hyderabad: 350 INR Desoldering Wick from a local shop in Hyderabad: 300 INR Journey While building the keyboard, I started with following the guide mentioned above, but It was not descriptive enough so I supplemented it with other guide for Lily58.","title":"For Science Keyboard"},{"content":"I want to have a high impact from my career and and more I think about trying that, I feel that it cannot be done by simply following one field.\nI have been in computer science field for a while and have dabled in machine-learning/data-science on the side. All the jobs that I have taken were also aligned to the either fintech or logistics. But I feel that to have better impact on my career, I require cross pollination of different fields to mix-match different ideas from different fields and add value to whatever work I do.\nI have been considering multiple future career/studiets that wish to pursue and there are few of the things that I have been interested in:\nWorking more closely to hardware, like: battery firmware, embedded systems, GPU programming, etc. Learning more about biological world, and I feel that the way to step into it through learning it with something that I already know, like: https://github.com/ossu/bioinformatics I have been dabbling in machine-learning/data-science, and also have done multiple courses and certifications, but I never got to work on it full time; so having an opportunity there might also help me. Working in civil services and seeing the issues the people and government faces and trying to help them with my experience in technology. Starting my own business and growing it, which I think will teach me about lots of things like Delegating, Negotiating, Hiring, Execution, Finance, etc. Working in Commerce and Finance to learn managing, saving and growing money and how technology can help in doing it better. For examle: https://zerodha.com/varsity/ I still feel like I can do more, learn more, help more and hope that I get to work in all kind of fields, businesses and situtations.\n","permalink":"https://upendra1997.github.io/posts/diversify-career/","summary":"I want to have a high impact from my career and and more I think about trying that, I feel that it cannot be done by simply following one field.\nI have been in computer science field for a while and have dabled in machine-learning/data-science on the side. All the jobs that I have taken were also aligned to the either fintech or logistics. But I feel that to have better impact on my career, I require cross pollination of different fields to mix-match different ideas from different fields and add value to whatever work I do.","title":"Diversifying Career"},{"content":"I use direnv to automatically get into flake shell as soon as I entre the directory which contain the flake.nix, the content of .envrc file is:\nuse flake Most of the time I just need to use the package available in my shell for my dev work and the snipet that I use is:\n{ inputs = { nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-unstable\u0026#34;; flake-utils.url = \u0026#34;github:numtide/flake-utils\u0026#34;; }; outputs = { self, nixpkgs, flake-utils }: flake-utils.lib.eachDefaultSystem (system: let pkgs = import nixpkgs { inherit system; }; buildInputs = with pkgs; [ # package1 # package2 ]; in with pkgs; { devShells.default = mkShell { inherit buildInputs; }; } ); } Sometime I write custom scrips that I need access to, I can create a nixified version using the writeShellApplication which is one of the trivial builders. Bottom is just a simple shell script to get the authentication code simlar to google-authenticator:\n{ config, pkgs, ... }: with pkgs; writeShellApplication { name = \u0026#34;totp\u0026#34;; runtimeInputs = with pkgs; [ cloak ]; text = \u0026#39;\u0026#39; cloak view some_app | tr -d \u0026#39;\\n\u0026#39; | pbcopy \u0026#39;\u0026#39;; } and for new projects I use nix flake templates from nix flake show templates using nix flake init -t 'templates#go-hello'\nI will keep adding to this post if I find someting that I use often.\n","permalink":"https://upendra1997.github.io/posts/nix-snippets/","summary":"I use direnv to automatically get into flake shell as soon as I entre the directory which contain the flake.nix, the content of .envrc file is:\nuse flake Most of the time I just need to use the package available in my shell for my dev work and the snipet that I use is:\n{ inputs = { nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-unstable\u0026#34;; flake-utils.url = \u0026#34;github:numtide/flake-utils\u0026#34;; }; outputs = { self, nixpkgs, flake-utils }: flake-utils.","title":"Nix Snippets"},{"content":"This is a snippet for benchmarking clojure application which I have used quite often in clojure applications at my job.\nFirst an introduction to the tools:\nclj-asyc-profiler: for flamegraphs and call graph. criterion: for statistically correct benchmarking. tufte: application level profiling. from this we can keep both #1 and #2 in separate profile just for benchmarking and #3 must be included in the :default profile, otherwise it would defeat its purpose.\nbelow is the code snippet for having these libraries setup in project:\n(defproject clojure-benchmark \u0026#34;0.1.0-SNAPSHOT\u0026#34; :description \u0026#34;snippets to setup benchamrking tests in clojure\u0026#34; :url \u0026#34;http://example.com/FIXME\u0026#34; :license {:name \u0026#34;EPL-2.0 OR GPL-2.0-or-later WITH Classpath-exception-2.0\u0026#34; :url \u0026#34;https://www.eclipse.org/legal/epl-2.0/\u0026#34;} :test-selectors {:default (complement :bench) :not (fn [m s] (not (contains? m (keyword s)))) :bench :bench} :dependencies [[org.clojure/clojure \u0026#34;1.11.1\u0026#34;] [com.taoensso/tufte \u0026#34;2.4.5\u0026#34;]] :profiles {:test [{:dependencies [[org.clojure/test.check \u0026#34;1.1.1\u0026#34;] [criterium \u0026#34;0.4.6\u0026#34;]]}] :bench [{:test-paths [\u0026#34;bench\u0026#34;] :global-vars {*assert* true} :jvm-opts [\u0026#34;-Djdk.attach.allowAttachSelf\u0026#34; \u0026#34;-XX:+UnlockDiagnosticVMOptions\u0026#34; \u0026#34;-XX:+DebugNonSafepoints\u0026#34;] :dependencies [[com.clojure-goes-fast/clj-async-profiler \u0026#34;1.0.4\u0026#34;]]} :test]} :repl-options {:init-ns clojure-benchmark.core}) important points to note are:\nWe have created a new source locaction called bench, this is added so that all of these overhead of benchmarking is not included in production code, and it can be isolated to run during local run or pipeline run. There are :test-selectors being added so that we can specifically mark some test to be benchmark tests and run only them using lein with-profile +bench test :bench. The overhead mentioned above will be due to including below functionlities in the code:\nRunnig flamgraph profiling for the whole duration of the benchmark run. Making sure that tufte check all the namespaces for gathering the application level metrics. Making sure that all benchmark are being written to a file. The code for above mentioned functionalities is:\n(ns clojure-benchmark.bench (:require [clojure.java.io :as io] [clj-async-profiler.core :as prof] [taoensso.tufte :as tufte])) ;; necessary to print it so that jvm know that we are using its result (def prof-started (let [start (atom (prof/start {})) _ (println \u0026#34;profiling started.\u0026#34; (prof/status))] @start)) (alter-var-root #\u0026#39;tufte/*ns-filter* (constantly \u0026#34;*\u0026#34;)) ;; accumulator for tufte result (def stats-accumulator (tufte/add-accumulating-handler! {:ns-pattern \u0026#34;*\u0026#34;})) ;; before exiting make sure that we are printing profiling result (System/setSecurityManager (proxy [SecurityManager] [] (checkExit [status] (let [_ (println \u0026#34;profiling ended.\u0026#34; (prof/status)) _ (io/make-parents \u0026#34;profiling-result/random-file\u0026#34;) result (prof/stop) file-name (.getName result)] (io/make-parents (format \u0026#34;profiling-result/%s\u0026#34; file-name)) (io/copy result (io/as-file (format \u0026#34;profiling-result/%s\u0026#34; file-name))) (with-open [writer (io/writer (format \u0026#34;profiling-result/tufte-prof-%d.txt\u0026#34; (System/currentTimeMillis)))] (.write writer (tufte/format-grouped-pstats @stats-accumulator))))) (checkCreateClassLoader [\u0026amp; args] true) (checkPermission [\u0026amp; args] true))) (ns clojure-benchmark.util (:require [clojure.java.io :as io] [clojure.test :refer :all])) (defn write-to-file [file-name f \u0026amp; args] (let [file-name (format \u0026#34;profiling-result/%s\u0026#34; file-name) _ (io/make-parents file-name)] (with-open [file (io/writer file-name)] (binding [*out* file] (apply f args))))) Please check the sample test to understand how to use write the benchmark\n(ns clojure-benchmark.core-test (:require [clojure.test :refer :all] [taoensso.tufte :refer :all] [criterium.core :refer [benchmark report-result]] [clojure-benchmark.util :refer [write-to-file]] [clojure-benchmark.core :refer :all])) (defn fib [n] (cond (\u0026lt;= n 0) 0 (= n 1) 1 :else (+ (fib (- n 1)) (fib (- n 2))))) (defn noob-fib [n] (p :pro (fib n))) (def lazy-fib (lazy-cat [0 1] (map + lazy-fib (rest lazy-fib)))) (defn pro-fib [n] (p :pro (nth lazy-fib n))) (deftest a-test (testing \u0026#34;test\u0026#34; (is (= (noob-fib 10) 55)) (is (= (noob-fib 10) 55)) (is (= (pro-fib 13) 233)) (is (= (pro-fib 13) 233)))) (deftest ^:bench benchmark-fib (profile {} (let [input [10 13] noob-fib (benchmark (doseq [inp input] (noob-fib inp)) {:verbose true :runtime true}) pro-fib (benchmark (doseq [inp input] (pro-fib inp)) {:verbose true :runtime true})] (write-to-file \u0026#34;pro-fib.txt\u0026#34; report-result pro-fib :verbose :os :runtime) (write-to-file \u0026#34;noob-fib.txt\u0026#34; report-result noob-fib :verbose :os :runtime)))) and its output for lein test:\nlein test clojure-benchmark.core-test Ran 1 tests containing 4 assertions. 0 failures, 0 errors. lein with-profile +bench test :bench\nprofiling started. Profiling is running for 0 seconds lein test clojure-benchmark.core-test Ran 1 tests containing 0 assertions. 0 failures, 0 errors. profiling ended. Profiling is running for 182 seconds Profiling started output of tufte:\n:tufte/nil-id, pId nCalls Min 50% ≤ 90% ≤ 95% ≤ 99% ≤ Max Mean MAD Clock Total :pro 89,481,254 421.00ns 1.46μs 1.77μs 2.38μs 3.69μs 204.07ms 1.28μs ±50% 1.91m 68% :tufte/compaction 111 34.23ms 110.15ms 147.70ms 283.73ms 325.88ms 919.43ms 103.33ms ±54% 11.47s 7% Accounted 2.10m 75% Clock 2.81m 100% output of benchmark:\n[hdggxin@nixos:~/workspace/clojure-benchmark/profiling-result]$ cat noob-fib.txt amd64 Linux 6.1.51 4 cpu(s) OpenJDK 64-Bit Server VM 25.362-bga Runtime arguments: -Dfile.encoding=UTF-8 -Djdk.attach.allowAttachSelf -XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints -Dclojure.compile.path=/ home/hdggxin/workspace/clojure-benchmark/target/classes -Dclojure-benchmark.version=0.1.0-SNAPSHOT -Dclojure.debug=false Evaluation count : 2773980 in 60 samples of 46233 calls. Execution time sample mean : 21.751842 µs Execution time mean : 21.807202 µs Execution time sample std-deviation : 2.868742 µs Execution time std-deviation : 2.972753 µs Execution time lower quantile : 20.927824 µs ( 2.5%) Execution time upper quantile : 25.620445 µs (97.5%) Overhead used : 2.454320 ns Found 13 outliers in 60 samples (21.6667 %) low-severe 4 (6.6667 %) low-mild 9 (15.0000 %) Variance from outliers : 80.7320 % Variance is severely inflated by outliers [hdggxin@nixos:~/workspace/clojure-benchmark/profiling-result]$ cat pro-fib.txt amd64 Linux 6.1.51 4 cpu(s) OpenJDK 64-Bit Server VM 25.362-bga Runtime arguments: -Dfile.encoding=UTF-8 -Djdk.attach.allowAttachSelf -XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints -Dclojure.compile.path=/ home/hdggxin/workspace/clojure-benchmark/target/classes -Dclojure-benchmark.version=0.1.0-SNAPSHOT -Dclojure.debug=false Evaluation count : 34700400 in 60 samples of 578340 calls. Execution time sample mean : 1.807223 µs Execution time mean : 1.808515 µs Execution time sample std-deviation : 165.871690 ns Execution time std-deviation : 166.917813 ns Execution time lower quantile : 1.516781 µs ( 2.5%) Execution time upper quantile : 2.079813 µs (97.5%) Overhead used : 2.454320 ns and finally the flamegraph: please check full sample repo here: https://github.com/upendra1997/clojure-benchmark\n","permalink":"https://upendra1997.github.io/posts/benchmarking-clojure-application/","summary":"This is a snippet for benchmarking clojure application which I have used quite often in clojure applications at my job.\nFirst an introduction to the tools:\nclj-asyc-profiler: for flamegraphs and call graph. criterion: for statistically correct benchmarking. tufte: application level profiling. from this we can keep both #1 and #2 in separate profile just for benchmarking and #3 must be included in the :default profile, otherwise it would defeat its purpose.","title":"Benchmarking Clojure Application"},{"content":"I was trying to explore the files available in resource directory and read only the .txt files available.\nsuppose that I have these files in resources:\nresources/ └── hello ├── a.txt ├── b.txt └── c.not-txt and this is the clojure code that I have to read the files:\n(ns jar-resource-read.core (:require [clojure.java.io :refer [resource file]]) (:gen-class)) (defn read-all-txt-files [] (let [txt-files (-\u0026gt;\u0026gt; (resource \u0026#34;hello\u0026#34;) (file) (file-seq) (filter #(-\u0026gt; %1 (.getName) (.endsWith \u0026#34;.txt\u0026#34;))))] (for [f txt-files] {:name (.getName f) :content (slurp f)}))) (defn -main [\u0026amp; args] (doseq [{file-name :name content :content} (read-all-txt-files)] (println (format \u0026#34;%s:\u0026#34; file-name)) (println content) (println \u0026#34;---------------\u0026#34;))) and running lein run actually returns the correct result:\nb.txt: hello --------------- a.txt: hi --------------- but when I try to creat a jar using lein uberjar and run the jar java -jar target/uberjar/jar-resource-read-0.1.0-SNAPSHOT-standalone.jar, but this is the error that I got:\nException in thread \u0026#34;main\u0026#34; java.lang.IllegalArgumentException: Not a file: jar:file:/home/hdggxin/workspace/jar-resource-read/target/uberjar/jar-resource-read-0.1.0-SNAPSHOT-standalone.jar!/hello at clojure.java.io$fn__11513.invokeStatic(io.clj:61) at clojure.java.io$fn__11513.invoke(io.clj:44) at clojure.java.io$fn__11487$G__11469__11492.invoke(io.clj:35) at clojure.java.io$file.invokeStatic(io.clj:424) at jar_resource_read.core$read_all_txt_files.invokeStatic(core.clj:5) at jar_resource_read.core$_main.invokeStatic(core.clj:16) at jar_resource_read.core$_main.doInvoke(core.clj:16) at clojure.lang.RestFn.invoke(RestFn.java:397) at clojure.lang.AFn.applyToHelper(AFn.java:152) at clojure.lang.RestFn.applyTo(RestFn.java:132) at jar_resource_read.core.main(Unknown Source) further looking into it, found that there are two main reasons for these errors:\njar is a compressed file. file-seq requires a file as argument. so basically file-seq cannot iterate over a location in compressed archive, i.e. jar:file:/home/hdggxin/workspace/jar-resource-read/target/uberjar/jar-resource-read-0.1.0-SNAPSHOT-standalone.jar!/hello\nWe can uncompress the jar during the program startup and iterate over the extracted location, but this will make program not run through lein, so finally decided to read the file during the compile time and put the object in jar.\nwhich can be done using:\n(defmacro all-txt-files [] (into [] (read-all-txt-files))) and then using this macro we can change the main function:\n(defn -main [\u0026amp; args] (doseq [{file-name :name content :content} (all-txt-files)] (println (format \u0026#34;%s:\u0026#34; file-name)) (println content) (println \u0026#34;---------------\u0026#34;))) This obviously solves the issue and we get the same output using the jar files also :) Please check the full code here.\n","permalink":"https://upendra1997.github.io/posts/exploring-resource-directory-in-clojure/","summary":"I was trying to explore the files available in resource directory and read only the .txt files available.\nsuppose that I have these files in resources:\nresources/ └── hello ├── a.txt ├── b.txt └── c.not-txt and this is the clojure code that I have to read the files:\n(ns jar-resource-read.core (:require [clojure.java.io :refer [resource file]]) (:gen-class)) (defn read-all-txt-files [] (let [txt-files (-\u0026gt;\u0026gt; (resource \u0026#34;hello\u0026#34;) (file) (file-seq) (filter #(-\u0026gt; %1 (.getName) (.","title":"Exploring Resource Directory in Clojure"},{"content":"AOC-2023-5 If You Give A Seed A Fertilizer This problem was hardest yet and took longest to solve. so the problem asks us to create a map from seed to location such as:\nseed -\u0026gt; soil -\u0026gt; fertilizer -\u0026gt; water -\u0026gt; light -\u0026gt; temprature -\u0026gt; humidity -\u0026gt; location where we are given certain mappings from one entity to another, eg: seed 1 corresponds to soil 10 and given this mapping and intial seed list we need to find the minimum location.\nPart 1 In this part we are given list of intial seeds, and mapping, which we use to construct the Data.Map and traverse it.\nAn interesting choice was to handle entries which were not provided in the mapping, so basically if given key is not present in the map then we look into trasition map, which map over entities to functions(which map from entity to entity). eg: if soil 12 was not found in the map then we look for soil INT_MIN in transition map, which will return a function that will take soil 12 and returns fertilizer 12.\ncheck toLocation function to understand the approach mentioned above.\nPart 2 In this part we are givent ranges of seeds intead of just few seeds. If we go with the previous approach, our Map will become very large since it cannot contains that many elements and we will reach out of memory very soon.\nOther approach to solve the issue is to not fit all of them into memory and consider ranges as an entity. We will represent seed 5 to 10 as Seed(5, 10) and we will find all the intersecting entities and we will keep doing until we reach the location entity.\nsuppose that we had the mapping:\nSeed(2, 7) -\u0026gt; Soil(10, 15) Seed(9, 15) -\u0026gt; Soil(20, 26) then the intersections and ther mapping would be:\nintersection -\u0026gt; mapping Seed(5, 7) -\u0026gt; Soil(13, 15) Seed(9, 10) -\u0026gt; Soil(20, 21) Seed(7, 9) -\u0026gt; Soil(7, 9) To speed up solution and preventing code going into infintite recursion, we will be using the State Monad from mtl to keep track of visited nodes and use Data.Tree from containers library to explore the search space.\ncheck locationsFn for the approach mentioned above. Please use the drawForest in code to visualize the search space and note that the code is not that readable :(\n","permalink":"https://upendra1997.github.io/posts/advent-of-code-2023-day-5/","summary":"AOC-2023-5 If You Give A Seed A Fertilizer This problem was hardest yet and took longest to solve. so the problem asks us to create a map from seed to location such as:\nseed -\u0026gt; soil -\u0026gt; fertilizer -\u0026gt; water -\u0026gt; light -\u0026gt; temprature -\u0026gt; humidity -\u0026gt; location where we are given certain mappings from one entity to another, eg: seed 1 corresponds to soil 10 and given this mapping and intial seed list we need to find the minimum location.","title":"Advent of Code 2023 Day 5"},{"content":"AOC-2023-4 Scratchcards This problem was easy in the sense that it required just required correct parsing and following the rules to get the result in the problem.\nPart 1 Part 1 just required correct parsing and computing the solution.\nPart 2 Part 2, says that for each winning card with n numbers, we will get extra copies of next n cards, so to maintain the number of extra cards we used a state monad, to keep track of how may extra copies each card have. We use that information to multiply our score with that.\nSolution is available at: https://github.com/upendra1997/advent-of-code-2023-hs/blob/main/day4/day4.hs\n","permalink":"https://upendra1997.github.io/posts/advent-of-code-2023-day-4/","summary":"AOC-2023-4 Scratchcards This problem was easy in the sense that it required just required correct parsing and following the rules to get the result in the problem.\nPart 1 Part 1 just required correct parsing and computing the solution.\nPart 2 Part 2, says that for each winning card with n numbers, we will get extra copies of next n cards, so to maintain the number of extra cards we used a state monad, to keep track of how may extra copies each card have.","title":"Advent of Code 2023 Day 4"},{"content":"AOC-2023-3 Gear Ratios In this problem, we had to parse the input problem and find all the symbols like: #, *, + and $. All numbers that are adjacent to symbols are important for us, and we need to compute the result.\nPart 1 In this part we had to compute the sum of numbers adjacent to the symbol decsribed above. To get the results I was going for the graph traversal algorithm, and to do that in haskell I used containers library to get Data.Tree and used State Monad from mtl to keep track of visited nodes using get and put.\nTo Debug the issue during the development, I used drawForest in the code using Debug.Trace and used the hardcoded input and running the :main in REPL again and again.\nPart 2 In this part we had to find the pair of numbers around * and multiply them and sum all the results from that.\nSo the solution is available at: https://github.com/upendra1997/advent-of-code-2023-hs/blob/main/day3/day3.hs\nbut please note that helperFunction and main are not that readable :(\n","permalink":"https://upendra1997.github.io/posts/advent-of-code-2023-day-3/","summary":"AOC-2023-3 Gear Ratios In this problem, we had to parse the input problem and find all the symbols like: #, *, + and $. All numbers that are adjacent to symbols are important for us, and we need to compute the result.\nPart 1 In this part we had to compute the sum of numbers adjacent to the symbol decsribed above. To get the results I was going for the graph traversal algorithm, and to do that in haskell I used containers library to get Data.","title":"Advent of Code 2023 Day 3"},{"content":"AOC-2023-2 Cube Conundrum In this problem, we have to parse the input text and compute the result; this problem was not particularly hard or tricky and just required correct parsing.\ncode for day 2 is at: https://github.com/upendra1997/advent-of-code-2023-hs/blob/main/day2/day2.hs\n","permalink":"https://upendra1997.github.io/posts/advent-of-code-2023-day-2/","summary":"AOC-2023-2 Cube Conundrum In this problem, we have to parse the input text and compute the result; this problem was not particularly hard or tricky and just required correct parsing.\ncode for day 2 is at: https://github.com/upendra1997/advent-of-code-2023-hs/blob/main/day2/day2.hs","title":"Advent of Code 2023 Day 2"},{"content":"AOC-2023-1 Trebuchet?! I have tried solving advent of code 2023 challenges in haskell, and this was my attempt to solve day 1. In this problem we have to find the first and last digits in a line and sum them.\nproblem link: https://adventofcode.com/2023/day/1\nPart 1 First part is very simple as it is just a parsing problem, and we can use my favourite library for parsing: parsec to solve it.\nPart 2 Second part have a variation that say the digits may be spelled out like one instead of 1. which seems to be easy to solve as we can just change our parsing logic to consider both 1 and one as 1. But when I treid to solve it using that approach, I was getting the wrong result.\nso I thought that I am missing an edge case; i.e.: twone, which should return 21. There are two issues here that needs to be solved:\nWe don\u0026rsquo;t want to consume the input stream event though we have found the matching token. We want our parser to be greedy for searching the first digit and lazy for searching the last digit. To understand the issues, we need to understad how parsec works.\nparesc consumes the input stream and at each returns the token found and rest of the input stream, so for our example it would be:\none way to solve the issue is to run the parser at every character and collect the result, like so:\nbut that seemed to be very complicated, so I decided to reverse the string and run the parser with a switch to reverse the string.\nyou can check the code at: https://github.com/upendra1997/advent-of-code-2023-hs/blob/main/day1/day1.hs\n","permalink":"https://upendra1997.github.io/posts/advent-of-code-2023-day-1/","summary":"AOC-2023-1 Trebuchet?! I have tried solving advent of code 2023 challenges in haskell, and this was my attempt to solve day 1. In this problem we have to find the first and last digits in a line and sum them.\nproblem link: https://adventofcode.com/2023/day/1\nPart 1 First part is very simple as it is just a parsing problem, and we can use my favourite library for parsing: parsec to solve it.","title":"Advent of Code 2023 Day 1"},{"content":"I have never been consistent with my writing and I wish to change it to become better at writing; and Internet is a place where we can express ourself. so this is me being accountable and putting myself out.\nNow, I will be trying to write about:\ndaily-life things I learned explaining something snippets anything else I will be trying to stick with it.\n","permalink":"https://upendra1997.github.io/posts/putting-yourself-out/","summary":"I have never been consistent with my writing and I wish to change it to become better at writing; and Internet is a place where we can express ourself. so this is me being accountable and putting myself out.\nNow, I will be trying to write about:\ndaily-life things I learned explaining something snippets anything else I will be trying to stick with it.","title":"Putting Yourself Out"},{"content":"I created a new video and google slide explaining visitor pattern:\nYoutube Video: Google Slide: references: Google Slide Gangs Of Four Book awesome blog about clojure design patterns: http://mishadoff.com/blog/clojure-design-patterns/#episode-4-visitor ","permalink":"https://upendra1997.github.io/posts/visitor-pattern/","summary":"I created a new video and google slide explaining visitor pattern:\nYoutube Video: Google Slide: references: Google Slide Gangs Of Four Book awesome blog about clojure design patterns: http://mishadoff.com/blog/clojure-design-patterns/#episode-4-visitor ","title":"Visitor Pattern"},{"content":"Last time, I mentioned that I tried to write sudoku solver in haskell and it was using too much memory and time. So I tried to solve it again and this time I was able to do it, I guess I just needed more motivation.\nWe will be using this file format as input to our suodku program:\n92634.7.1 .5..264.9 .7.8.1... ...9..2.7 342.....5 1.....8.. 6854...12 ..4..29.. .1.538.7. and it will be represented as an array of numbers and . will be represented as 0, so for our repl, the sudoku will be [[Int]]\n[[9, 2, 6, 3, 4, 0, 7, 0, 1], [0, 5, 0, 0, 2, 6, 4, 0, 9], [0, 7, 0, 8, 0, 1, 0, 0, 0], [0, 0, 0, 9, 0, 0, 2, 0, 7], [3, 4, 2, 0, 0, 0, 0, 0, 5], [1, 0, 0, 0, 0, 0, 8, 0, 0], [6, 8, 5, 4, 0, 0, 0, 1, 2], [0, 0, 4, 0, 0, 2, 9, 0, 0], [0, 1, 0, 5, 3, 8, 0, 7, 0]] above sudoku only have one solution, but there could be sudokus with multiple solutions also, like:\n[[2, 9, 5, 7, 4, 3, 8, 6, 1], [4, 3, 1, 8, 6, 5, 9, 0, 0], -- 2 7 [8, 7, 6, 1, 9, 2, 5, 4, 3], [3, 8, 7, 4, 5, 9, 2, 1, 6], [6, 1, 2, 3, 8, 7, 4, 9, 5], [5, 4, 9, 2, 1, 6, 7, 3, 8], [7, 6, 3, 5, 2, 4, 1, 8, 9], [9, 2, 8, 6, 7, 1, 3, 5, 4], [1, 5, 4, 9, 3, 8, 6, 0, 0]] -- 7 2 or we could have empty sudoku, which will give us all the valid sudokus possible in the world:\n[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]] Project Structure This is created by using stack new suokdu\n. ├── CHANGELOG.md ├── LICENSE ├── README.md ├── Setup.hs ├── app │ └── Main.hs ├── emptySudoku.txt -- empty sudoku input file. ├── package.yaml ├── src │ └── Lib.hs ├── stack.yaml ├── stack.yaml.lock ├── sudoku.cabal ├── sudoku.txt -- only one solution sudoku file. └── test └── Spec.hs Defining Types here we will be defining a few of the types which will be used in our program, all of them are type aliases type instead of newtype as I wanted to use these types interchangeably with generic functions like crossProduct, which we will see later.\n-- src/Lib.hs type Cell = Int type SudokuSize = Int type Row = [Int] type X = Int type Y = Int type Coord = (X, Y) -- Coordinates type Sudoku = [Row] Config We will be storing some configs like sudokuSize and the gridSize in the Sudoku in the Lib.hs file.\n-- src/Lib.hs sudokuSize :: SudokuSize sudokuSize = 9 blockSize :: Int blockSize = 3 Parsing and printing Sudoku We need to pretty print our sudoku in the terminal, so for that, we will be defining showSudoku function:\n-- src/Lib.hs showRow :: Show a =\u0026gt; [a] -\u0026gt; String showRow row = unwords $ show \u0026lt;$\u0026gt; row showSudoku :: Show a =\u0026gt; [[a]] -\u0026gt; String showSudoku sudoku = unlines $ showRow \u0026lt;$\u0026gt; sudoku and to parse our sudoku from the file we will define below the functions:\n-- app/main.hs module Main (main) where import Data.Char (digitToInt) import Control.Monad (replicateM) import Lib (Cell, Row, sudokuSize, showSudoku) parseChar :: Char -\u0026gt; Cell parseChar \u0026#39;.\u0026#39; = 0 parseChar x = digitToInt x parseString :: String -\u0026gt; Row parseString = map parseChar readRow :: IO Row readRow = do row \u0026lt;- parseString \u0026lt;$\u0026gt; getLine if length row /= sudokuSize then error \u0026#34;row does not have the correct number of cells\u0026#34; else return row main :: IO () main = do sudoku \u0026lt;- replicateM sudokuSize readRow mapM_ (putStrLn . showSudoku) [sudoku] We have defined a function readRow which will read from stdin and try to parse it as a Row, and since readRow is an IO, i.e. it reads from the terminal, we can use replicateM to repeat this operation and read multiple rows from the terminal.\nif we look at the type of replicateM in the stack repl, we will see that:\nghci\u0026gt; :t replicateM replicateM :: Applicative m =\u0026gt; Int -\u0026gt; m a -\u0026gt; m [a] so here (Int -\u0026gt; m a) -\u0026gt; m [a] means that it will collect a from m type of computation and will return a new computation m [a] where all the a have been gathered from different computations. i.e. so here (9 -\u0026gt; readRow) replicateM needs a number 9 and a computation to replicate which is readRow, and it will return IO [Row] which is a sudoku.\nsimilarly in MapM function, where _ will ignore the result:\nghci\u0026gt; :t mapM mapM :: (Traversable t, Monad m) =\u0026gt; (a -\u0026gt; m b) -\u0026gt; t a -\u0026gt; m (t b) ghci\u0026gt; :t mapM_ mapM_ :: (Foldable t, Monad m) =\u0026gt; (a -\u0026gt; m b) -\u0026gt; t a -\u0026gt; m () Validate Sudokus for a sudoku to be valid, each row and column must contain a number from 1 to 9 exactly once; and also there are 9 grids of size 3x3 in a 9x9 sudoku, where no number must repeat.\nget all rows -- src/lib.hs rows :: [[a]] -\u0026gt; [[[a]]] rows = fmap (replicate sudokuSize) get all columns -- src/lib.hs columns :: [[a]] -\u0026gt; [[[a]]] columns = transpose . rows . transpose get all grid blocks to get all grid blocks we need to know which grid each element of sudoku belongs to, every grid has a start and end position which can be represented by Coord type.\nCoordinates of all elements in sudoku:\n-- src/lib.hs coordinates :: [[Coord]] coordinates = [[(r, c) | c \u0026lt;- [0 .. sudokuSize - 1]] | r \u0026lt;- [0 .. sudokuSize - 1]] block coordinate will give us the start and end position pairs of all sudoku elements.\n-- src/lib.hs blockCoordinates :: [[(Coord, Coord)]] blockCoordinates = (fmap . fmap) (\\(x, y) -\u0026gt; (start x y, end x y)) coordinates where start x\u0026#39; y\u0026#39; = (3 * (x\u0026#39; `div` blockSize), 3 * (y\u0026#39; `div` blockSize)) end x\u0026#39; y\u0026#39; = (\\(x\u0026#39;\u0026#39;, y\u0026#39;\u0026#39;) -\u0026gt; (x\u0026#39;\u0026#39; + blockSize, y\u0026#39;\u0026#39; + blockSize)) $ start x\u0026#39; y\u0026#39; if Sudoku type was parametrized like:\ntype Sudoku a = [[a]] then we could have represented blockCoordinates as:\ntype Rectangle = (Coord, Coord) -- (start, end) blockCoordinates :: [[Rectangle]] to get values from block coordinates we need a few helper functions like slice and slice2D\n-- src/lib.hs slice :: Int -\u0026gt; Int -\u0026gt; [a] -\u0026gt; [a] slice start end = drop start . take end -- src/lib.hs slice2D :: [[a]] -\u0026gt; Int -\u0026gt; Int -\u0026gt; Int -\u0026gt; Int -\u0026gt; [[a]] slice2D sudoku startRow endRow startCol endCol = slice startRow endRow $ slice startCol endCol \u0026lt;$\u0026gt; sudoku and finally, our function to get blocks at each coordinate:\n-- src/lib.hs blocks :: Sudoku -\u0026gt; [[[[Int]]]] blocks sudoku = (fmap . fmap) block blockCoordinates where getSlice = slice2D sudoku block ((startRow, startCol), (endRow, endCol)) = getSlice startRow endRow startCol endCol to understand it better, lets take our previous case where Sudoku was parametrized, which would give us\nblocks :: Sudoku -\u0026gt; Sudoku (Sudoku Int) here blocks is like a sudoku of sudokus, where inner sudoku is a 3x3 grid.\nfinally, we merge all the values of the rows, column and grid values at each coordinate of the grid and we get:\n-- src/lib.hs getAllValues :: Sudoku -\u0026gt; [[[Cell]]] getAllValues sudoku = (fmap . fmap) (sort . nub) all\u0026#39; where add\u0026#39; = (zipWith . zipWith) (++) all\u0026#39; = add\u0026#39; blocks\u0026#39; $ add\u0026#39; rows\u0026#39; cols\u0026#39; rows\u0026#39; = rows sudoku cols\u0026#39; = columns sudoku blocks\u0026#39; = fmap concat \u0026lt;$\u0026gt; blocks sudoku and alternate way would to see this would be if Suodku was parametrized\ngetAllValues :: Sudoku -\u0026gt; Sudoku [Int] this tells us that each sudoku element is an array of integers.\nand by this scenario, we can easily validate sudoku if all the elements of sudoku contain exactly 9 values\n-- src/lib.hs valid :: Sudoku -\u0026gt; Bool valid sudoku = (all . all) (== 9) (fmap length \u0026lt;$\u0026gt; getAllValues sudoku) Sudoku Solutions getting solutions without context The easiest solution would be to try 1 to 9 values for each 0 in the sudoku. the time complexity of this would be 9^n where n is the number of 0 in the sudoku. We already know that this solution is very slow, and we will never get any answer. But let\u0026rsquo;s see how it would be implemented in haskell.\nfirst, we need a helper function that would give us all possible values for each element:\n-- src/Lib.hs possibilities :: Cell -\u0026gt; [Cell] possibilities 0 = [1 .. 9] possibilities n = [n] then we need a way to cross-produce each possibility. Here cross-product is the same as the cross-product of a set in mathematics.\nghci\u0026gt; crossProduct [[1, 2, 3], [4, 5], [6]] [[1,4,6],[1,5,6],[2,4,6],[2,5,6],[3,4,6],[3,5,6]] and here is its implementation:\n-- src/Lib.hs crossProduct :: [[a]] -\u0026gt; [[a]] crossProduct [] = [] crossProduct [a] = [[x] | x \u0026lt;- a] crossProduct (array : rest) = (:) \u0026lt;$\u0026gt; array \u0026lt;*\u0026gt; crossProduct rest we could also use the sequence function from Prelude, which does the same thing.\nghci\u0026gt; :t sequence sequence :: (Traversable t, Monad m) =\u0026gt; t (m a) -\u0026gt; m (t a) ghci\u0026gt; sequence [[1,2,3], [4,5], [6]] [[1,4,6],[1,5,6],[2,4,6],[2,5,6],[3,4,6],[3,5,6]] So by getting a cross-product of each possibility we will get all solutions available.\n-- src/Lib.hs getSolutions :: Sudoku -\u0026gt; [Sudoku] getSolutions sudoku = filter valid allSudokus where allSudokus = crossProduct (crossProduct . fmap possibilities \u0026lt;$\u0026gt; sudoku) so for this kind of solution, we have these many possibilities:\nghci\u0026gt; product $ fmap product $ fmap (length . possibilities) \u0026lt;$\u0026gt; sudoku 8599843895832833305 Which is a lot\u0026hellip;\ngetting solutions based on context now, we can be smarter about this and only generate possibilities which are not already present in the row, column and grid blocks.\n-- src/Lib.hs possibilitiesWithContext :: Sudoku -\u0026gt; Coord -\u0026gt; [Cell] possibilitiesWithContext sudoku coord = if currentValue == 0 then possibleValues else [currentValue] where (x, y) = coord currentValue = head $ concat $ slice2D sudoku x (x + 1) y (y + 1) -- sudoku !! x !! y allValues\u0026#39; = getAllValues sudoku allValues = concatMap concat $ slice2D allValues\u0026#39; x (x + 1) y (y + 1) possibleValues = [0..sudokuSize] \\\\ allValues -- subtract a from b | `a` \\\\ `b` and will be plugging it in the getSolutions approach.\n-- src/Lib.hs getSolutions :: Sudoku -\u0026gt; [Sudoku] getSolutions sudoku = filter valid allSudokus where possibilities\u0026#39; = possibilitiesWithContext sudoku allSudokus = crossProduct (crossProduct . fmap possibilities\u0026#39; \u0026lt;$\u0026gt; coordinates) ghci\u0026gt; product $ fmap product $ fmap (length . possibilities\u0026#39;) \u0026lt;$\u0026gt; coordinates 2972033482752 for this solution, almost 1000000 times fewer searches have to be done for this; but still slow for our computer.\ngenerating solutions based on context We can have a faster solution if for each coordinate with 0 we take one possible number and try to generate possibilities for other holes in the sudoku, if at some point we reach a hole in the sudoku where there is no possible number, then we backtrack to the previous hole and try next possibility, once we are done will all the holes in the sudoku, we return our solution.\nfor this approach, we would need a helper function that would replace our sudoku with given coordinates and a new value.\n-- src/Lib.hs replaceAt :: Int -\u0026gt; (a -\u0026gt; a) -\u0026gt; [a] -\u0026gt; [a] -- works for 1D array replaceAt index f array = left ++ (f current : right\u0026#39;) where (left, right) = splitAt index array current = head right right\u0026#39; = tail right and so finally our solution\n-- src/Lib.hs generateSudoku :: [Coord] -\u0026gt; Sudoku -\u0026gt; [Sudoku] generateSudoku [] sudoku\u0026#39; = do guard (valid sudoku\u0026#39;) return sudoku\u0026#39; generateSudoku (coord: coords) sudoku\u0026#39; = do let (x, y) = coord let values = possibilitiesWithContext sudoku\u0026#39; coord guard $ (not . null) values val \u0026lt;- values let sudoku\u0026#39;\u0026#39; = replaceAt x (replaceAt y (const val)) sudoku\u0026#39; generateSudoku coords sudoku\u0026#39;\u0026#39; Let\u0026rsquo;s break it down. coords is a list of coordinates where we have holes = 0. generateSudoku is a function that will try to replace coord with a possibility and will backtrack if no possibility is present at some point using guard.\nand let\u0026rsquo;s plug it into our solution\n-- src/Lib.hs getSolutions :: Sudoku -\u0026gt; [Sudoku] getSolutions sudoku = generateSudoku coords\u0026#39; sudoku where coords\u0026#39; = concatMap (fmap filter id ifValid) coordinates -- concat $ (fmap.fmap filter id) ifValid coordinates ifValid (x, y) = 0 == (sudoku !! x !! y) Printing all solutions so finally our main function looks like:\n-- app/Main.hs main :: IO () main = do sudoku \u0026lt;- replicateM sudokuSize readRow mapM_ (putStrLn . showSudoku) $ getSolutions sudoku and our solution is\n9 2 6 3 4 5 7 8 1 8 5 1 7 2 6 4 3 9 4 7 3 8 9 1 5 2 6 5 6 8 9 1 3 2 4 7 3 4 2 6 8 7 1 9 5 1 9 7 2 5 4 8 6 3 6 8 5 4 7 9 3 1 2 7 3 4 1 6 2 9 5 8 2 1 9 5 3 8 6 7 4 Github Repository: https://github.com/upendra1997/sudoku-haskell\n","permalink":"https://upendra1997.github.io/posts/haskell-sudoku/","summary":"Last time, I mentioned that I tried to write sudoku solver in haskell and it was using too much memory and time. So I tried to solve it again and this time I was able to do it, I guess I just needed more motivation.\nWe will be using this file format as input to our suodku program:\n92634.7.1 .5..264.9 .7.8.1... ...9..2.7 342.....5 1.....8.. 6854...12 ..4..29.. .1.538.7. and it will be represented as an array of numbers and .","title":"Haskell Sudoku"},{"content":"Hello world, I am Upendra Upadhyay. This is my first post and I have been trying to write for a long time. I think there is no better time than now.\nI have been trying to learn Haskell for past 3 years in my free time, but was never able to code anything useful; mostly did fibonacci, sieve of eratosthenes, and sudoku - which was taking lot of memory and time because of bad pruning.\nFibonacci fib = 0:1:zipWith (+) fib (tail fib) ghci\u0026gt; take 10 fib [0,1,1,2,3,5,8,13,21,34] Sieve of eratosthenes sieve (p:ps) = p:sieve (filter (\\x -\u0026gt; x `mod` p /= 0) ps) prime = sieve [2..] ghci\u0026gt; take 10 prime [2,3,5,7,11,13,17,19,23,29] All things considered, I was never able to be productive in Haskell, But I got opportunity to work in Clojure; which allowed me to write functional code and interop with Java/Javascript. It created a bridge to Haskell, which have great ideas with steep learning curve.\nSimilar case is with Rust, I am still trying to solve Xorcism , never seem to be getting closer to solution. I think Rust have great ideas but also a bit of learning curve. This where I think Nim can become similar bridge like Clojure for Rust. It allows system programming and interop with C, C++, Javascript.\nwhich makes me curious to learn Nim.\n","permalink":"https://upendra1997.github.io/posts/nim-clojure-similarity/","summary":"Hello world, I am Upendra Upadhyay. This is my first post and I have been trying to write for a long time. I think there is no better time than now.\nI have been trying to learn Haskell for past 3 years in my free time, but was never able to code anything useful; mostly did fibonacci, sieve of eratosthenes, and sudoku - which was taking lot of memory and time because of bad pruning.","title":"Nim Clojure Similarity"}]